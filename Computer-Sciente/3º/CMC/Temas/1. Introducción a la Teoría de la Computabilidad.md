La teoría de a computación es una rama de las matemáticas que centra su interés en las limitaciones y capacidades fundamentales de las computadoras para a resolución de problemas. Específicamente esta teoría busca modelos matemáticos que formalicen el concepto de *haver un cómputo* (cuenta o cálculo) y la clasificación de problemas de acuerdo a esos modelos. Esta teoría explora los límites de la posibilidad de solucionar problemas mediante **algoritmos**. Gran parte de las ciencias computacionales están dedicadas a resolver problemas de forma algorítmica, de manera que el descubrimiento de **problemas irresolubles** es útil para no tratar de resolver algorítmicamente estos problemas, ahorrando tiempo y esfuerzo.

Obviando los trabajos de algunos matemáticos (Leibniz, Pascal, etc.) podemos estableces que los fundamentos de la teoría de la computación se realizaron durante la primera mitad del siglo XX. Matemáticos como A. Church, A. Turin, K Gödel, S. Kleene y E. Post (entre otros) crearon los fundamentos de la Teoría de la Computabilidad que, hoy en día, es una parte fundamental de la Informática Teórica (*Theoretical Computer Science*).

Además, esta teoría engloba (o puede describir) otras subramas de conocimiento fundamentales en la informática teórica:
* Teoría de autómatas (o máquinas formales).
*  Teoría de los lenguajes formales.
* Teoría de la complejidad computacional.

## El Programa de Hilbert

Formulado por el matemático alemán David Hilbert en la década de 1920, fue una solución propuesta ante la crisis fundacional de las matemáticas, en épocas en que en los primeros intentos por clarificar los fundamentos de la matemática contenían paradojas e inconsistencias. Como solución, Hilbert propuso basarse en todas las teorías existentes para formar un conjunto de axiomas finito y completo, y proveer prueba de que esos axiomas eran consistentes. El alemán propuso que la consistencia de sistemas más complicados, como el análisis real, podrían ser probados en térmios de sistemas más simples. Últimamente, la consistencia de toda la matemática puede ser reducida a aritmética básica.

## Teoremas de incompletitud de Gödel

Son dos célebres teoremas de lógica matemática demostrados por Kurt Gödel en 1931. Ambos están relacionados con la existencia de [**proposiciones indecidibles**](https://es.wikipedia.org/wiki/Problema_indecidible) en ciertas teorías airméticas.

El **primer teorema de incompletitud** afirma que, bajo ciertas condiciones, ninguna teoría matemática formal capaz de describir los números naturales y la aritmética son suficiente expresividad , es a la vez consistente y completa. Es decir, si los axiomas de dicha teoría no se contradicen entre sí, entonces existen enunciados que no puden probarse ni refutarse (usando sólo las reglas de deducción de dicha teoría). Las teorías aritméticas para las que el teorema es válido son básicamente aquellas en las que la deducción de teoremas pude realizarse mediante un algoritmo (y por tanto el conjunto de axiomas sea recursivamente enumerable).

El ***Entscheindungsproblem*** (en castellano: problema de decisión) fue el reto en lógica simbólica de encontrar un algoritmo general que decidiera si una fórmula de cálculo de primer orden es un teorema. En 1928, David Hilber y Wilhelm Ackermann propusieon la **pregunta** en su formulación anteriormente mencionada.

## Cálculo Lambda y Máquina de Turin

Antes de poder responde a esa pregunta, hubo que definir formalmente la noción de algoritmo. Esto fue realizado por Alonzo Church en 1936 con el concepto de "calculabilidad efectiva" basada en su **cálculo lambda** y por Alan Turing basándose en la **máquina de Turing**.

La respuesta negativa al ***Entscheindungsproblem*** fue dada por Alonzo Church en 1936 e independientemente, muy poco tiempo después, por Alan Turing, también en 1936. Church demostró que no existe algoritmo (definido según las funciones recursivas) que decida para dos expresiones del cálculo lambda si son equivalentes o no. Por otra parte, Turing redujo este problema al problema de la parada para las máquinas de Turing. Ambos trabajos se vieron influidos por trabajos anteriores de Kurt Gödel sobre el teorema de incompletitud, especialmente por el método de asignar números a las fórmulas lógicas para poder reducir la lógica aritmética.


# Otras perspectivas

Otras perspectiva radicalmente distinta es la que se contempla en lo que ho en día se conoce como **computación natural**. La computación natural forma parte de la computación no convencional y toma como funete de inspiración los fenómenos naturales (atómicos, bioquímicos, evolutivos, etc.) y el tratamiento de la información que se realiza en los mismos.

La computación natural re-define el concepto de algoritmo formulando nuevos modelos de computación equivalentes a la máquina de Turing.

Estos modelos pueden ser abstractos y la plausibilidad de su implementación real es materia de investigación en la actualidad. Fundamentalmente, se están investigando nuevos materiales (nano-bio-mecánicos) que cambien el paradigma actual de las computadoras electrónicas basadas en la tecnología del silicio hacia computadoras bioquímicas que tomen como sustrato las bio-macromoléculas (el ADN, el ARN, las proteinas, etc.).

Nacen nuevas disciplinas que integran la biología, la física y la computación: la biología sintética y la nanocomputación son dos ajemplos reales de estas disciplinas.

Además, los fenómenos naturales se estudian bajo otro prisma que integra la teoría de la información  y la teoría de la computación. Áreas de conocimiento como la biología de sistemas y la cosmología integran hoy en día este nuevo paradigma.

# Conclusiones

* La teoría de la computabilidad propone la definición de algoritmo y establece los límites de los problemas que se pueden resolver de forma algorítmica.
* Propone nuevos modelos de cálculo que pueden tener una implicación real en las tecnologías informáticas futuras.
* Explica de forma exhaustiva las capacidades de la tecnología informática actual y da cuenta de sus limitaciones. La teoría de la computabilidad engloba a la Ingeniría Informática como un caso particular de la tecnología actual.
* Propone un marco matemático que explica otras disciplinas y áreas de estudio bajo un nuevo prisma formal.
